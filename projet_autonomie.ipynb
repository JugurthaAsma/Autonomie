{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Réalisation du projet en autonomie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chargement des librairies\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "import time\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# les classes\n",
    "CLASSES = [\"Cat\", \"Cow\", \"Dog\", \"Elephant\", \"Panda\"]\n",
    "\n",
    "#Chargement des images\n",
    "def load_data() :\n",
    "\n",
    "    # import images from ./transfert/{class}/img.*\n",
    "    X = []\n",
    "    label = []\n",
    "    for c in CLASSES:\n",
    "        # lire de dossier \"./transfert/{c} et charger les images\n",
    "        DIRNAME = f\"./transfert/{c}\"\n",
    "\n",
    "        for img_name in os.listdir(DIRNAME):\n",
    "            # charger l'image\n",
    "            img = cv2.imread(DIRNAME + \"/\" + img_name)\n",
    "            # redimensionner l'image en 224 224  et ramener l'image entre 0 et 1\n",
    "            img = np.float32((cv2.resize(img, (224, 224)))) / 255.0\n",
    "            # ajouter l'image dans X\n",
    "            X.append(img)\n",
    "            # ajouter le label dans label\n",
    "            label.append(CLASSES.index(c))\n",
    "\n",
    "\n",
    "\n",
    "    dim_img = (224, 224, 3)\n",
    "    X = np.array(X)\n",
    "\n",
    "    # target \n",
    "    Target = np.zeros((len(X), len(CLASSES)), 'int')\n",
    "    for i in range(len(X)):\n",
    "        Target[i, label[i]] = 1\n",
    "\n",
    "    return X, Target, label, dim_img\n",
    "\n",
    "\n",
    "# chargement des données\n",
    "X, Target, label, dim_img = load_data()\n",
    "\n",
    "# creation d'un ensemble de test et d'apprentissage et affichage d'exemple\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Target, test_size=0.2, random_state=1)\n",
    "\n",
    "# affichage d'exemple\n",
    "plt.figure(figsize=(10, 10))\n",
    "for i in range(9):\n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(X_train[i])\n",
    "    plt.title(CLASSES[np.argmax(y_train[i])])\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# util (show accuracy and confusion matrix, and loss)\n",
    "def show_metrics(Y_test, Y_pred, history, name = \"\"):\n",
    "\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(15, 3))\n",
    "\n",
    "    # show accuracy at the first column\n",
    "    axes[0].set_title('Accuracy ' + name)\n",
    "    axes[0].plot(history.history['accuracy'], 'g--' )\n",
    "    axes[0].plot(history.history['val_accuracy'], 'g')\n",
    "    axes[0].legend(['Training', 'Validation'])\n",
    "\n",
    "    # show confusion matrix in another row\n",
    "    confusionMatrix = confusion_matrix(np.argmax(Y_test, axis=1), np.argmax(Y_pred, axis=1))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=confusionMatrix, display_labels=CLASSES)\n",
    "    disp.plot(include_values=True, cmap=plt.cm.Blues, ax=axes[1], xticks_rotation='vertical')\n",
    "    axes[1].set_title('Confusion Matrix ' + name)\n",
    "\n",
    "    # show loss at the second column\n",
    "    axes[2].set_title('Loss ' + name)\n",
    "    axes[2].plot(history.history['loss'], 'r--' )\n",
    "    axes[2].plot(history.history['val_loss'], 'r')\n",
    "    axes[2].legend(['Training', 'Validation'])\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "# fonction qui lance l'entrainement d'un model avec des hyperparametres donnés et calcule le temps\n",
    "def launch_train(model, X_train, y_train, X_test, y_test, epochs, batch_size, learning_rate=0.001, loss=\"categorical_crossentropy\", name = \"\"):\n",
    "\n",
    "    # compile model\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=learning_rate), loss=loss, metrics=['accuracy'])\n",
    "\n",
    "    # train model\n",
    "    start_time = time.time()\n",
    "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test))\n",
    "    print(\"Temps d'entrainement : %s secondes ---\" % (time.time() - start_time))\n",
    "\n",
    "    # evaluate model\n",
    "    Y_pred = model.predict(X_test)\n",
    "    show_metrics(y_test, Y_pred, history, name)\n",
    "\n",
    "    print(\"####### entrainement de \" + name + \" avec \" + str(epochs) + \" epochs, \" + str(batch_size) + \" batch_size et \" + str(learning_rate) + \" et un learning_rate de \" + str(learning_rate) + \" #######\") \n",
    "\n",
    "def plot_image(image):\n",
    "    plt.imshow(image, cmap=\"binary\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "def projection_image(model, images, n_images=4):\n",
    "    reconstructions = model.predict(images[:n_images])\n",
    "    fig = plt.figure(figsize=(n_images * 1.5, 3))\n",
    "    for image_index in range(n_images):\n",
    "        plt.subplot(2, n_images, 1 + image_index)\n",
    "        plot_image(images[image_index])\n",
    "        plt.subplot(2, n_images, 1 + n_images + image_index)\n",
    "        plot_image(reconstructions[image_index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commenter les opérations de chargement et de création des bases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure imposée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création de la structure\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(64, 3, activation='relu', padding='same', input_shape=dim_img),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2), padding='same'),\n",
    "    keras.layers.Conv2D(32, 3, activation='relu', padding='same'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2), padding='same'),\n",
    "    keras.layers.Conv2D(16, 3, activation='relu', padding='same'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2), padding='same'),\n",
    "\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(len(CLASSES), activation='softmax')\n",
    "])\n",
    "#Apprentissage de la structure\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrainement du modèle\n",
    "#MEsure du temsp d'apprentissage\n",
    "start_time = time.time()\n",
    "history = model.fit(X_train, y_train, epochs=20, batch_size=12, validation_split=0.2)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "PREDICTION = model.predict(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Etude des courbes d'apprentissage\n",
    "show_metrics(y_test, PREDICTION, history, \"CNN\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commentaire sur l'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Etude des résultats globaux et par classe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commentaire sur l'efficience du modèle et conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure libre mais à complexité contrôlée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création de la structure\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(64, 3, activation='relu', padding='same', input_shape=dim_img),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2), padding='same'),\n",
    "    keras.layers.Conv2D(32, 3, activation='relu', padding='same'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2), padding='same'),\n",
    "    keras.layers.Conv2D(16, 3, activation='relu', padding='same'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2), padding='same'),\n",
    "\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(len(CLASSES), activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apprentissage de la structure\n",
    "\n",
    "hyperparams = [\n",
    "    [2, 12, 0.001],\n",
    "\n",
    "]\n",
    "\n",
    "for hyperparam in hyperparams:\n",
    "    launch_train(model, X_train, y_train, X_test, y_test, hyperparam[0], hyperparam[1], hyperparam[2], \"categorical_crossentropy\", \"CNN\")\n",
    "\n",
    "\n",
    "#MEsure du temsp d'apprentissage\n",
    "#Etude des courbes d'apprentissage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test avec plusieur couche "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commentaire sur l'apprentissage et sur les choix faits pour la structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Etude des résultats globaux et par classe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commentaire sur l'efficience du modèle, comparaison avec le premier modèle et conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Structure libre mais à discrimination optimale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création de la structure\n",
    "# utiliser inceptionV3\n",
    "model_transfere = InceptionV3(\n",
    "    input_shape=dim_img,\n",
    "    classes=len(CLASSES),\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    classifier_activation=\"softmax\",\n",
    ")\n",
    "\n",
    "for layer in model_transfere.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "x = model_transfere.output\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = keras.layers.Dense(512, activation='relu')(x)\n",
    "out = keras.layers.Dense(5, activation='softmax')(x)\n",
    "\n",
    "model = keras.Model(inputs=model_transfere.input, outputs=out)\n",
    "# Apprentissage de la structure\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=20, batch_size=12, validation_split=0.2)\n",
    "\n",
    "PREDICTION = model.predict(X_test)\n",
    "\n",
    "show_metrics(y_test, PREDICTION, history, \"InceptionV3\")\n",
    "\n",
    "\n",
    "\n",
    "#Apprentissage de la structure\n",
    "model.save('my_modele')\n",
    "#MEsure du temsp d'apprentissage\n",
    "#Etude des courbes d'apprentissage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commentaire sur l'apprentissage et sur les choix faits pour la structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Etude des résultats globaux et par classe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commentaire sur l'efficience du modèle, comparaison avec les premiers modèles et conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Création d'une structure autoencodeur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# codeur correspond à la structure imposée\n",
    "encoder = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(64, 3, activation='relu', padding='same', input_shape=dim_img),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2), padding='same'),\n",
    "\n",
    "    keras.layers.Conv2D(32, 3, activation='relu', padding='same'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2), padding='same'),\n",
    "    \n",
    "    keras.layers.Conv2D(16, 3, activation='relu', padding='same'),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2), padding='same'),\n",
    "\n",
    "])\n",
    "\n",
    "# décodeur\n",
    "decoder = keras.models.Sequential([\n",
    "    keras.layers.UpSampling2D((2, 2)),\n",
    "    keras.layers.Conv2D(16, 3, activation='relu', padding='same'),\n",
    "    keras.layers.UpSampling2D((2, 2)),\n",
    "    keras.layers.Conv2D(32, 3, activation='relu', padding='same'),\n",
    "    keras.layers.UpSampling2D((2, 2)),\n",
    "    keras.layers.Conv2D(64, 3, activation='relu', padding='same'),\n",
    "    keras.layers.Conv2D(3, 3, activation='softmax', padding='same', input_shape=dim_img ),\n",
    "])\n",
    "\n",
    "autoencoder_dr = keras.models.Sequential([encoder, decoder])\n",
    "# Apprentissage avec comme fonction de cout mse\n",
    "autoencoder_dr.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "history = autoencoder_dr.fit(X, X, epochs=10, batch_size=16, validation_split=0.2)\n",
    "\n",
    "PREDICTION = autoencoder_dr.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Etude des courbes d'apprentissage\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(15, 2))\n",
    "\n",
    "# show accuracy at the first column\n",
    "axes[0].set_title('Accuracy AUTOENCODER')\n",
    "axes[0].plot(history.history['accuracy'], 'g--' )\n",
    "axes[0].plot(history.history['val_accuracy'], 'g')\n",
    "axes[0].legend(['Training', 'Validation'])\n",
    "\n",
    "\n",
    "# show loss at the second column\n",
    "axes[1].set_title('Loss ')\n",
    "axes[1].plot(history.history['loss'], 'r--' )\n",
    "axes[1].plot(history.history['val_loss'], 'r')\n",
    "axes[1].legend(['Training', 'Validation'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commentaire sur l'apprentissage et sur les choix faits pour la structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Projection d'images de la base\n",
    "\n",
    "projection_image(autoencoder_dr, X, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commentaire sur la qualité d'approximation de votre autoencodeur évaluée par traitement de différentes images de la base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfert learning du codeur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# récupération du codeur de l'autoencodeur\n",
    "# Ajout de couche de prise de décision\n",
    "# Apprentissage en bloquant les poids du codeur\n",
    "for layer in encoder.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commentaire sur l'apprentissage et sur la structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Etude des résultats globaux et par classe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commentaire sur l'efficience du modèle, comparaison avec le premier modèle et conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Influence du bruit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ma_fonction(Data):\n",
    "    Data_b = Data.copy()\n",
    "    for nb in range(0,len(Data)):\n",
    "        Data_b[nb] = Data[nb]+(np.random.rand(Data[nb].shape[0],Data[nb].shape[1],Data[nb].shape[2])*0.7)\n",
    "    Data_b = np.clip(Data_b,0.,1.)\n",
    "    return Data_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expliciter ce que réalise cette fonction et indiquant l'opération réalisée par chaque ligne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test sur la meilleure structure \n",
    "my_model = keras.models.load_model('modele')\n",
    "X_test_b = ma_fonction(X_test)\n",
    "test_loss, test_acc = model.evaluate(X_test_b, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commenter les opérations, évaluer les résultats par rapport à ceux obtenus sur X_test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencodeur contre le bruit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "4428cbe1ba9314b3551257500664b995dcc328d303584ff4cad6f1a703111ed9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
